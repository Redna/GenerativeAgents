{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbc9b0b-f0ea-48e3-951c-1e813de3a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/alex/environments/lab_env/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: requests in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/alex/environments/lab_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: einops in /home/alex/environments/lab_env/lib/python3.10/site-packages (0.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.215-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hCollecting numexpr<3.0.0,>=2.8.4\n",
      "  Downloading numexpr-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.4/381.4 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting langchainplus-sdk>=0.0.17\n",
      "  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from langchain) (1.24.1)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /home/alex/environments/lab_env/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic, numexpr, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.17 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 greenlet-2.0.2 langchain-0.0.215 langchainplus-sdk-0.0.17 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 openapi-schema-pydantic-1.2.4 pydantic-1.10.9 tenacity-8.2.2 typing-inspect-0.9.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install einops\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da88e7e-6a8e-4968-81d1-1bc2d3f4bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36846562-3e2d-404c-baba-f344efeecdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d7a2b121474cd89a41d7d8dab727bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300fbe8427cf47bc8819105e8206d031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f7886dba8e4e7bb3a46213f6e28d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30ab19e614426fbfce5b663be8cf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d5c47a7b16446bb9ccac165f16d319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7ecac325794b2f82d51a8f4ec559ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "torch.random.seed = 0\n",
    "\n",
    "model_id = \"tiiuae/falcon-7b-instruct\" # \"tiiuae/falcon-7b\" #\"tiiuae/falcon-40b-instruct\" #\"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"left\")\n",
    "\n",
    "streamer = TextStreamer(tokenizer=tokenizer)\n",
    "\n",
    "generator = pipeline(\"text-generation\",\n",
    "                    model=model_id,\n",
    "                    tokenizer=tokenizer,\n",
    "                    torch_dtype=torch.bfloat16,\n",
    "                    trust_remote_code=True,\n",
    "                    device=0,\n",
    "                    max_length=500,\n",
    "                    do_sample=True,\n",
    "                    top_k=35,\n",
    "                    top_p=.89,\n",
    "                    temperature=.65,\n",
    "                    num_return_sequences=1,\n",
    "                    streamer=streamer,\n",
    "                    pad_token_id = tokenizer.eos_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4775c5-ceeb-4e95-8eb2-5f5a98d9f2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generative_agent.agent' from '/home/alex/Programming/generative-agent-sim/generative_agent/agent.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "from generative_agent import agent\n",
    "from generative_agent.agent import Agent, Dialogue, Action, Memory\n",
    "\n",
    "import importlib\n",
    "importlib.reload(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd697350-a684-4192-b04d-f1f06b8ef5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dfc3278-6600-400b-b844-af7096741a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "john_lin = Agent(\"John Lin\", \"\"\"John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. \n",
    "He is always looking for ways to make the process of getting medication easier for his customers; John Lin\n",
    "is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying \n",
    "music theory; John Lin loves his family very much;\"\"\", \"John is back home early from work.\")\n",
    "    \n",
    "eddy_lin = Agent(\"Eddy Lin\", \"\"\"Eddy Lyn is a student studying music theory. He is passionated about music an loves to do walks in the \n",
    "nature. Eddy lives together with his mother Mei Lin and his Father John Lin. He is a very friendly person\n",
    "and is always willing to help his friends.\"\"\", \"Eddy is taking a short walk around his workplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f614ac38-ce30-4766-9907-a9af99ca6d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lin is a pharmacy shopkeeper at the Willow Market and Pharmacy who loves to help people. \n",
      "He is always looking for ways to make the process of getting medication easier for his customers; John Lin\n",
      "is living with his wife, Mei Lin, who is a college professor, and son, Eddy Lin, who is a student studying \n",
      "music theory; John Lin loves his family very much;\n",
      "\n",
      "It is June 25, 2023, 10:57PM.\n",
      "John Lin's status: John is back home early from work.\n",
      "\n",
      "Observation: John saw Eddy taking a short walk around his workplace.\n",
      "\n",
      "Summary of relevant context from John Lin's memory:\n",
      "John Lin is Eddy Lin’s father. John Lin is caring and is interested to learn more about Eddy \n",
      "Lin’s school work. John Lin knows that Eddy Lin is working on a music composition.\n",
      "\n",
      "Should John Lin react to the observation, and if so, what would be an appropriate reaction?\n",
      "An appropriate reaction would be to smile at his son, Eddy Lin, and ask him how his day went. John Lin is also curious to know about his son’s school work, so he can ask him questions related to it. If Eddy is taking a walk around his workplace, it is reasonable for John Lin to assume that his son is off the clock. However, if John\n",
      "\n",
      "An appropriate reaction would be to smile at his son, Eddy Lin, and ask him how his day went. John Lin is also curious to know about his son’s school work, so he can ask him questions related to it. If Eddy is taking a walk around his workplace, it is reasonable for John Lin to assume that his son is off the clock.\n"
     ]
    }
   ],
   "source": [
    "relevant_memory = john_lin.memory.memory_for(eddy_lin)\n",
    "john_observation = \"John saw Eddy taking a short walk around his workplace.\"\n",
    "\n",
    "john_action = Action(tokenizer, generator).generate(john_lin, john_observation, relevant_memory)\n",
    "print(john_action[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72285045-254a-4cfa-80ea-fca508fdd231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John Lin: Hey, how was your day today?\n",
      "\n",
      "Eddy Lin: Hey, it was a pretty good day. I finished my composition early, so I decided to take a short walk around the workplace.\n",
      "\n",
      "John Lin: That’s great! I’m glad to hear that you finished your composition early. Did you have any other plans for\n"
     ]
    }
   ],
   "source": [
    "dialogue = Dialogue(tokenizer, generator)\n",
    "\n",
    "dialogue_history = []\n",
    "\n",
    "dialogue_history.append(dialogue.start(john_lin, eddy_lin, john_observation, relevant_memory, john_action[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fccd0228-b435-4760-bc17-4d6ea8911003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lin: \"Hey, how was your day today?\"\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_history[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bc9a16a-3187-4262-8ac7-f3eeeb07aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John Lin: \"It was a good day. I finished my work early. I'm glad to be home early. How was your day?\"\n",
      "\n",
      "What would Eddy Lin say to John Lin?\n",
      "Eddy Lin: \"I'm glad to hear that you finished your work early. I'm working on a music composition. I'\n"
     ]
    }
   ],
   "source": [
    "observation = \"John is in a conversation with Eddy\"\n",
    "relevant_memory = john_lin.memory.memory_for(eddy_lin)\n",
    "\n",
    "dialogue_history.append(dialogue.turn(john_lin, eddy_lin, observation, relevant_memory, [turn for turn,_,_ in dialogue_history]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17b9d6c9-7356-494b-9867-a8584a7fcd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lin: \"It was a good day. I finished my work early. I'm glad to be home early. How was your day?\"\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_history[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9df83d91-7683-40ef-b2b6-283087491fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eddy Lin: \"It was a good day too. I finished my work early and I went for a walk in the nature. It was a nice walk. I enjoyed it.\"\n",
      "\n",
      "What would John Lin say to Eddy Lin?\n",
      "John Lin: \"That's great to hear. I'm glad that you enjoyed your walk. Do\n"
     ]
    }
   ],
   "source": [
    "observation = \"Eddy is in a conversation with John\"\n",
    "relevant_memory = eddy_lin.memory.memory_for(john_lin)\n",
    "\n",
    "dialogue_history.append(dialogue.turn(eddy_lin, john_lin, observation, relevant_memory, [turn for turn,_,_ in dialogue_history]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ed8be72-2516-44fa-a3b1-96e22558831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lin: \"Hey, how was your day today?\"\n",
      "John Lin: \"It was a good day. I finished my work early. I'm glad to be home early. How was your day?\"\n",
      "Eddy Lin: \"It was a good day too. I finished my work early and I went for a walk in the nature. It was a nice walk. I enjoyed it.\"\n"
     ]
    }
   ],
   "source": [
    "for turn,_,_ in dialogue_history:\n",
    "    print(turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f305a13-4413-453d-8d10-3f96d42778e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue_history\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      3\u001b[0m action_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mGiven the following dialogue:\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mShould John <continue> or <leave> the conversation?\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "h = '\\n'.join(dialogue_history[:5])  \n",
    "\n",
    "action_prompt = f\"\"\"\n",
    "Given the following dialogue:\n",
    "{h}\n",
    "\n",
    "Should John <continue> or <leave> the conversation?\"\"\"\n",
    "        \n",
    "with torch.no_grad():\n",
    "    action = generator(action_prompt, \n",
    "                    max_length=len(tokenizer.encode(action_prompt)) + 30,\n",
    "                    do_sample=True,\n",
    "                    top_k=0,\n",
    "                    top_p=.80,\n",
    "                    temperature=.7,\n",
    "                    streamer = None,\n",
    "                    pad_token_id = tokenizer.eos_token_id\n",
    "                    )\n",
    "    \n",
    "print(action[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c75f3-fdc5-45bc-84a2-0c379f9e8a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env",
   "language": "python",
   "name": "lab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
